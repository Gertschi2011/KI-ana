# ğŸš€ Phase 2: Lokale Autonomie - Arbeitsplan

**Zeitraum:** Q4 2025 - 3 Monate (Nov 2025 - Jan 2026)  
**Start:** 23. Oktober 2025  
**Ziel:** KI_ana lÃ¤uft vollstÃ¤ndig lokal ohne Server-AbhÃ¤ngigkeit

---

## ğŸ¯ Phase 2 Hauptziele

Aus dem Fahrplan:
1. **Lokale AI-Modelle** - Keine Cloud-APIs mehr
2. **Submind-System** - Jedes GerÃ¤t wird eigenstÃ¤ndig
3. **Offline-First Database** - SQLite statt PostgreSQL

---

## ğŸ“… Wochenplan (12 Wochen)

### **Woche 1-2: Lokale Embeddings** ğŸ”¤
**Ziel:** Sentence-Transformers lokal statt OpenAI

**Tasks:**
- [ ] sentence-transformers installieren & testen
- [ ] Embedding-Service erstellen (`system/local_embeddings.py`)
- [ ] Qdrant mit lokalen Embeddings fÃ¼ttern
- [ ] Performance-Vergleich (OpenAI vs. lokal)
- [ ] Migration bestehender Embeddings

**Technologie:**
```python
from sentence_transformers import SentenceTransformer

# Modelle:
- all-MiniLM-L6-v2 (klein, schnell)
- all-mpnet-base-v2 (grÃ¶ÃŸer, besser)
- multilingual-e5-base (mehrsprachig)
```

**Erfolgskriterien:**
- âœ… Embeddings werden lokal generiert
- âœ… Keine OpenAI API Calls mehr
- âœ… Performance akzeptabel (<500ms)
- âœ… QualitÃ¤t vergleichbar

---

### **Woche 3-4: Lokale TTS/STT** ğŸ¤ğŸ”Š
**Ziel:** Sprache ohne Cloud

**Tasks:**
- [ ] Whisper.cpp fÃ¼r STT integrieren
- [ ] Piper-TTS fÃ¼r TTS integrieren
- [ ] Audio-Pipeline erstellen
- [ ] Voice-Interface testen
- [ ] Latenz optimieren

**Technologie:**
```bash
# STT (Speech-to-Text)
whisper.cpp - Lokales Whisper-Modell
Modelle: tiny, base, small, medium

# TTS (Text-to-Speech)
piper-tts - Hochqualitative lokale TTS
Stimmen: de_DE, en_US, etc.
```

**Erfolgskriterien:**
- âœ… Voice Input funktioniert lokal
- âœ… Voice Output funktioniert lokal
- âœ… Latenz < 2 Sekunden
- âœ… QualitÃ¤t gut genug fÃ¼r Alltagsnutzung

---

### **Woche 5-6: SQLite Migration** ğŸ’¾
**Ziel:** Embedded Database statt PostgreSQL

**Tasks:**
- [ ] SQLAlchemy auf SQLite umstellen
- [ ] Migration-Script schreiben
- [ ] Daten von PostgreSQL zu SQLite migrieren
- [ ] Performance-Tests
- [ ] Fallback-Mechanismus (Hybrid-Mode)

**Technologie:**
```python
# Hybrid-Ansatz:
if os.getenv("SERVER_MODE") == "1":
    DATABASE_URL = "postgresql://..."
else:
    DATABASE_URL = "sqlite:///./kiana.db"
```

**Erfolgskriterien:**
- âœ… SQLite funktioniert als Drop-in Replacement
- âœ… Alle Features funktionieren
- âœ… Performance akzeptabel
- âœ… Migration ohne Datenverlust

---

### **Woche 7-8: ChromaDB Integration** ğŸ”
**Ziel:** Embedded Vector DB statt Qdrant

**Tasks:**
- [ ] ChromaDB installieren & testen
- [ ] Migration von Qdrant zu ChromaDB
- [ ] Embedding-Pipeline anpassen
- [ ] Search-FunktionalitÃ¤t testen
- [ ] Performance-Vergleich

**Technologie:**
```python
import chromadb

# Embedded Mode:
client = chromadb.Client()

# Persistent Mode:
client = chromadb.PersistentClient(path="./chroma_db")
```

**Erfolgskriterien:**
- âœ… ChromaDB lÃ¤uft embedded
- âœ… Vector Search funktioniert
- âœ… Performance vergleichbar mit Qdrant
- âœ… Keine externen Dependencies

---

### **Woche 9-10: Submind-System** ğŸ¤–
**Ziel:** Device-IdentitÃ¤t & Registrierung

**Tasks:**
- [ ] Device-ID Generierung (UUID)
- [ ] Submind-Registry erstellen
- [ ] Lokaler Memory pro Submind
- [ ] Submind-Rollen implementieren
- [ ] UI fÃ¼r Submind-Verwaltung

**Technologie:**
```python
# system/submind_manager.py
class Submind:
    id: str          # UUID
    name: str        # "Laptop", "Smartphone"
    role: str        # "primary", "secondary", "sensor"
    device_type: str # "desktop", "mobile", "iot"
    capabilities: List[str]
    
# Rollen (aus access_control.json):
- papa (Hauptsystem)
- creator (Entwickler-Zugriff)
- submind (Untergeordnetes System)
- sensor (Nur Daten sammeln)
```

**Erfolgskriterien:**
- âœ… Jedes GerÃ¤t hat eindeutige ID
- âœ… Subminds kÃ¶nnen sich registrieren
- âœ… Rollen-System funktioniert
- âœ… Lokaler Memory pro Submind

---

### **Woche 11-12: Integration & Testing** ğŸ§ª
**Ziel:** Alles zusammenfÃ¼hren & testen

**Tasks:**
- [ ] End-to-End Tests
- [ ] Performance-Optimierung
- [ ] Dokumentation schreiben
- [ ] Docker-Setup aktualisieren
- [ ] Deployment-Guide erstellen

**Tests:**
```bash
# Lokaler Modus (ohne Server):
- Embeddings generieren
- Voice Input/Output
- Vector Search
- Submind-Kommunikation
- Offline-FunktionalitÃ¤t

# Hybrid-Modus (mit Server):
- Sync zwischen Subminds
- Fallback auf Server
- Performance-Vergleich
```

**Erfolgskriterien:**
- âœ… Alle Features funktionieren lokal
- âœ… Keine Cloud-Dependencies mehr
- âœ… Performance akzeptabel
- âœ… Dokumentation vollstÃ¤ndig

---

## ğŸ› ï¸ Technologie-Stack (Phase 2)

### Neu hinzugefÃ¼gt:
```
AI/ML:
â”œâ”€â”€ sentence-transformers (Embeddings)
â”œâ”€â”€ whisper.cpp (STT)
â””â”€â”€ piper-tts (TTS)

Databases:
â”œâ”€â”€ SQLite (User Data)
â”œâ”€â”€ ChromaDB (Vector Search)
â””â”€â”€ DiskCache (Caching)

Networking:
â”œâ”€â”€ mDNS (Device Discovery)
â””â”€â”€ WebRTC (P2P, spÃ¤ter)
```

### Weiterhin verwendet:
```
Core:
â”œâ”€â”€ FastAPI (Backend)
â”œâ”€â”€ Ollama (LLM)
â””â”€â”€ Python 3.11+

Frontend:
â”œâ”€â”€ Static HTML/JS
â””â”€â”€ TailwindCSS
```

---

## ğŸ“Š Metriken & KPIs

### Performance-Ziele:
- **Embedding Generation:** < 500ms pro Text
- **Voice-to-Text:** < 2s Latenz
- **Text-to-Voice:** < 1s Latenz
- **Vector Search:** < 100ms
- **Database Queries:** < 50ms

### QualitÃ¤ts-Ziele:
- **Embedding Quality:** > 85% Similarity zu OpenAI
- **STT Accuracy:** > 90% Word Error Rate
- **TTS Quality:** MOS > 4.0
- **System Uptime:** > 99%

### Resource-Ziele:
- **RAM Usage:** < 4GB (mit allen Modellen)
- **Disk Space:** < 10GB (Modelle + Data)
- **CPU Usage:** < 50% idle, < 80% peak
- **Startup Time:** < 30s

---

## ğŸš§ Risiken & Mitigationen

### Risiko 1: Performance
**Problem:** Lokale Modelle zu langsam  
**Mitigation:** 
- Quantisierte Modelle verwenden
- GPU-Acceleration (CUDA/Metal)
- Caching aggressiv nutzen

### Risiko 2: Modell-GrÃ¶ÃŸe
**Problem:** Modelle zu groÃŸ fÃ¼r Mobile  
**Mitigation:**
- Tiered Models (tiny/small/medium)
- On-Demand Download
- Model Pruning

### Risiko 3: KompatibilitÃ¤t
**Problem:** Alte Features brechen  
**Mitigation:**
- Hybrid-Mode (Server + Lokal)
- Feature Flags
- Graduelle Migration

### Risiko 4: KomplexitÃ¤t
**Problem:** System wird zu komplex  
**Mitigation:**
- Modularer Aufbau
- Gute Dokumentation
- Automatisierte Tests

---

## ğŸ“ Deliverables

### Code:
- [ ] `system/local_embeddings.py`
- [ ] `system/local_tts.py`
- [ ] `system/local_stt.py`
- [ ] `system/submind_manager.py`
- [ ] `system/hybrid_db.py`

### Dokumentation:
- [ ] `docs/LOCAL_SETUP.md`
- [ ] `docs/SUBMIND_GUIDE.md`
- [ ] `docs/MIGRATION_GUIDE.md`
- [ ] `docs/PERFORMANCE_TUNING.md`

### Tests:
- [ ] `tests/test_local_embeddings.py`
- [ ] `tests/test_local_voice.py`
- [ ] `tests/test_submind.py`
- [ ] `tests/test_offline_mode.py`

### Deployment:
- [ ] Docker-Compose Update
- [ ] Systemd Services Update
- [ ] Installation Script
- [ ] Migration Script

---

## ğŸ¯ Definition of Done

Phase 2 ist abgeschlossen wenn:

1. âœ… **Lokale Modelle:**
   - Embeddings lokal generiert
   - TTS/STT funktioniert offline
   - Keine Cloud-API Calls mehr

2. âœ… **Submind-System:**
   - Device-Registrierung funktioniert
   - Rollen-System aktiv
   - Lokaler Memory pro Device

3. âœ… **Offline-First:**
   - SQLite als Primary DB
   - ChromaDB fÃ¼r Vectors
   - Volle FunktionalitÃ¤t ohne Internet

4. âœ… **QualitÃ¤t:**
   - Alle Tests passing
   - Performance-Ziele erreicht
   - Dokumentation vollstÃ¤ndig

5. âœ… **Deployment:**
   - Docker-Setup aktualisiert
   - Migration-Path dokumentiert
   - Production-Ready

---

## ğŸ”„ NÃ¤chste Schritte (Heute)

### Sofort starten:
1. âœ… Phase 1 Review abgeschlossen
2. â¬œ sentence-transformers installieren
3. â¬œ Erste Embedding-Tests
4. â¬œ Performance-Baseline messen

### Diese Woche:
- Lokale Embeddings zum Laufen bringen
- Erste Integration mit Qdrant
- Performance-Vergleich dokumentieren

---

**Erstellt:** 23. Oktober 2025, 06:40 Uhr  
**Status:** ğŸ“‹ Bereit zum Start  
**NÃ¤chstes Review:** 30. Oktober 2025 (Woche 1 Review)
