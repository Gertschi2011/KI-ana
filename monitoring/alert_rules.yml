groups:
  - name: ki-ana-slo
    rules:
      - alert: KiAnaHigh5xxRate
        expr: |
          (
            sum(increase(ki_ana_http_requests_total{status=~"5.."}[5m]))
            /
            clamp_min(sum(increase(ki_ana_http_requests_total[5m])), 1)
          ) > 0.005
        for: 5m
        labels:
          severity: page
        annotations:
          summary: "KI_ana high 5xx rate"
          description: "5xx rate > 0.5% over 5m"

      - alert: KiAnaChatP95LatencyHigh
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_http_request_duration_seconds_bucket{route_group="chat"}[10m])) by (le)
          ) > 2
        for: 10m
        labels:
          severity: page
        annotations:
          summary: "KI_ana chat p95 latency high"
          description: "p95(chat) > 2s over 10m"

      - alert: KiAnaQueueBacklogHigh
        expr: ki_ana_celery_queue_backlog > 200
        for: 10m
        labels:
          severity: ticket
        annotations:
          summary: "KI_ana queue backlog high"
          description: "Default Celery queue backlog > 200 for 10m"

      - alert: KiAnaWorkerDown
        expr: ki_ana_celery_worker_up == 0
        for: 2m
        labels:
          severity: page
        annotations:
          summary: "KI_ana worker heartbeat missing"
          description: "No worker heartbeat seen in the last ~20s"

      - alert: KiAnaDependencyDown
        expr: ki_ana_dependency_up{dependency=~"redis|qdrant|minio"} == 0
        for: 2m
        labels:
          severity: page
        annotations:
          summary: "KI_ana dependency down"
          description: "Dependency {{ $labels.dependency }} is unreachable from backend"
          runbook: "ops/runbooks/dependency_down.md"
          dashboard: "monitoring/grafana/dashboards/kiana-overview.json"

      - alert: KiAnaCeleryTaskFailureRateHigh
        expr: |
          (
            sum(rate(ki_ana_celery_task_total{status="failure"}[5m]))
            /
            clamp_min(sum(rate(ki_ana_celery_task_total[5m])), 1)
          ) > 0.05
        for: 10m
        labels:
          severity: page
        annotations:
          summary: "KI_ana Celery task failure rate high"
          description: "Task failure rate > 5% over 10m"
          runbook: "ops/runbooks/celery_failures.md"
          dashboard: "monitoring/grafana/dashboards/kiana-overview.json"

      - alert: KiAnaCeleryEmbedP95RuntimeHigh
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_celery_task_runtime_seconds_bucket{task="embed.text"}[10m])) by (le)
          ) > 2
        for: 10m
        labels:
          severity: ticket
        annotations:
          summary: "KI_ana embed.text p95 runtime high"
          description: "p95(embed.text) > 2s over 10m"
          runbook: "ops/runbooks/celery_runtime.md"
          dashboard: "monitoring/grafana/dashboards/kiana-overview.json"

      - alert: KiAnaCeleryIngestParseP95RuntimeHigh
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_celery_task_runtime_seconds_bucket{task="ingest.parse_file"}[10m])) by (le)
          ) > 2
        for: 10m
        labels:
          severity: ticket
        annotations:
          summary: "KI_ana ingest.parse_file p95 runtime high"
          description: "p95(ingest.parse_file) > 2s over 10m"
          runbook: "ops/runbooks/celery_runtime.md"
          dashboard: "monitoring/grafana/dashboards/kiana-overview.json"

      - alert: KiAnaCeleryAggStale
        expr: |
          (
            time() - ki_ana_celery_agg_last_update_seconds{task=~"embed\\.text|ingest\\.parse_file"}
          ) > 900
          and
          (
            ki_ana_celery_queue_backlog > 5
          )
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Celery aggregates stale while backlog is building ({{ $labels.task }})"
          description: "No aggregate updates for >15m and backlog >5 for 10m. Check worker health, Redis, or stuck tasks."
          runbook: "ops/runbooks/celery_stale.md"
          dashboard: "monitoring/grafana/dashboards/kiana-overview.json"

  - name: ki-ana-quality-slos
    rules:
      # ---- Recording rules (optional; speeds up Grafana) -----------------
      - record: ki_ana_quality_tool_error_rate_10m
        expr: |
          (
            sum(rate(ki_ana_chat_tool_calls_total{status="error"}[10m]))
            /
            clamp_min(sum(rate(ki_ana_chat_tool_calls_total[10m])), 1)
          )

      - record: ki_ana_quality_tool_error_rate_2h
        expr: |
          (
            sum(rate(ki_ana_chat_tool_calls_total{status="error"}[2h]))
            /
            clamp_min(sum(rate(ki_ana_chat_tool_calls_total[2h])), 1)
          )

      - record: ki_ana_quality_no_sources_rate_10m
        expr: |
          (
            sum(rate(ki_ana_chat_answers_without_sources_total{intent=~"factual|research"}[10m]))
            /
            clamp_min(sum(rate(ki_ana_chat_answer_duration_seconds_count{intent=~"factual|research"}[10m])), 1)
          )

      - record: ki_ana_quality_no_sources_rate_2h
        expr: |
          (
            sum(rate(ki_ana_chat_answers_without_sources_total{intent=~"factual|research"}[2h]))
            /
            clamp_min(sum(rate(ki_ana_chat_answer_duration_seconds_count{intent=~"factual|research"}[2h])), 1)
          )

      - record: ki_ana_quality_consent_prompt_rate_10m
        expr: |
          (
            sum(rate(ki_ana_learning_consent_total{kind="prompt"}[10m]))
            /
            clamp_min(sum(rate(ki_ana_chat_answer_duration_seconds_count[10m])), 1)
          )

      - record: ki_ana_quality_consent_prompt_rate_2h
        expr: |
          (
            sum(rate(ki_ana_learning_consent_total{kind="prompt"}[2h]))
            /
            clamp_min(sum(rate(ki_ana_chat_answer_duration_seconds_count[2h])), 1)
          )

      - record: ki_ana_quality_negative_feedback_rate_10m
        expr: |
          (
            sum(rate(ki_ana_chat_feedback_total{status="negative"}[10m]))
            /
            clamp_min(sum(rate(ki_ana_chat_feedback_total[10m])), 1)
          )

      - record: ki_ana_quality_negative_feedback_rate_2h
        expr: |
          (
            sum(rate(ki_ana_chat_feedback_total{status="negative"}[2h]))
            /
            clamp_min(sum(rate(ki_ana_chat_feedback_total[2h])), 1)
          )

      - record: ki_ana_quality_traffic_rps_5m
        expr: |
          sum(rate(ki_ana_chat_answer_duration_seconds_count[5m]))

      # ---- SLO-1: Latency p95 by intent (threshold-based) ----------------
      - alert: KiAnaQualityLatencyP95HighFastGeneral
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_chat_answer_duration_seconds_bucket{intent="general"}[10m])) by (le)
          ) > 2.0
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Latency p95 fast burn: general (>2.0s)"
          description: "p95 latency for intent=general is above 2.0s over 10m (fast burn)."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityLatencyP95HighSlowGeneral
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_chat_answer_duration_seconds_bucket{intent="general"}[2h])) by (le)
          ) > 2.0
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Latency p95 slow burn: general (>2.0s)"
          description: "p95 latency for intent=general is above 2.0s over 2h (slow burn)."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityLatencyP95HighFastTool
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_chat_answer_duration_seconds_bucket{intent="tool"}[10m])) by (le)
          ) > 6.0
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Latency p95 fast burn: tool (>6.0s)"
          description: "p95 latency for intent=tool is above 6.0s over 10m (fast burn)."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityLatencyP95HighSlowTool
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_chat_answer_duration_seconds_bucket{intent="tool"}[2h])) by (le)
          ) > 6.0
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Latency p95 slow burn: tool (>6.0s)"
          description: "p95 latency for intent=tool is above 6.0s over 2h (slow burn)."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityLatencyP95HighFastFactual
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_chat_answer_duration_seconds_bucket{intent="factual"}[10m])) by (le)
          ) > 8.0
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Latency p95 fast burn: factual (>8.0s)"
          description: "p95 latency for intent=factual is above 8.0s over 10m (fast burn)."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityLatencyP95HighSlowFactual
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_chat_answer_duration_seconds_bucket{intent="factual"}[2h])) by (le)
          ) > 8.0
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Latency p95 slow burn: factual (>8.0s)"
          description: "p95 latency for intent=factual is above 8.0s over 2h (slow burn)."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityLatencyP95HighFastResearch
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_chat_answer_duration_seconds_bucket{intent="research"}[10m])) by (le)
          ) > 8.0
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Latency p95 fast burn: research (>8.0s)"
          description: "p95 latency for intent=research is above 8.0s over 10m (fast burn)."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityLatencyP95HighSlowResearch
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_chat_answer_duration_seconds_bucket{intent="research"}[2h])) by (le)
          ) > 8.0
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Latency p95 slow burn: research (>8.0s)"
          description: "p95 latency for intent=research is above 8.0s over 2h (slow burn)."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityLatencyP95HighFastOther
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_chat_answer_duration_seconds_bucket{intent!~"general|tool|factual|research"}[10m])) by (le)
          ) > 6.0
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Latency p95 fast burn: other intents (>6.0s)"
          description: "p95 latency (all other intents) is above 6.0s over 10m (fast burn)."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityLatencyP95HighSlowOther
        expr: |
          histogram_quantile(
            0.95,
            sum(rate(ki_ana_chat_answer_duration_seconds_bucket{intent!~"general|tool|factual|research"}[2h])) by (le)
          ) > 6.0
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Latency p95 slow burn: other intents (>6.0s)"
          description: "p95 latency (all other intents) is above 6.0s over 2h (slow burn)."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      # ---- SLO-2: Tool error rate ----------------------------------------
      - alert: KiAnaQualityToolErrorRateHighFast
        expr: |
          (
            sum(rate(ki_ana_chat_tool_calls_total{status="error"}[10m]))
            /
            clamp_min(sum(rate(ki_ana_chat_tool_calls_total[10m])), 1)
          ) > 0.06
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Tool error rate fast burn (>6%)"
          description: "Tool errors elevated over last 10m."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityToolErrorRateHighSlow
        expr: |
          (
            sum(rate(ki_ana_chat_tool_calls_total{status="error"}[2h]))
            /
            clamp_min(sum(rate(ki_ana_chat_tool_calls_total[2h])), 1)
          ) > 0.03
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Tool error rate slow burn (>3%)"
          description: "Tool errors elevated over last 2h."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      # ---- SLO-3: Answers without sources (factual|research only) --------
      - alert: KiAnaQualityNoSourcesRateHighFast
        expr: |
          (
            sum(rate(ki_ana_chat_answers_without_sources_total{intent=~"factual|research"}[10m]))
            /
            clamp_min(sum(rate(ki_ana_chat_answer_duration_seconds_count{intent=~"factual|research"}[10m])), 1)
          ) > 0.10
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "No-sources proxy fast burn (>10%)"
          description: "Answers without sources elevated for factual|research over last 10m."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityNoSourcesRateHighSlow
        expr: |
          (
            sum(rate(ki_ana_chat_answers_without_sources_total{intent=~"factual|research"}[2h]))
            /
            clamp_min(sum(rate(ki_ana_chat_answer_duration_seconds_count{intent=~"factual|research"}[2h])), 1)
          ) > 0.07
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "No-sources proxy slow burn (>7%)"
          description: "Answers without sources elevated for factual|research over last 2h."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      # ---- SLO-4: Consent prompt rate (anti-spam) ------------------------
      - alert: KiAnaQualityConsentPromptRateHighFast
        expr: |
          (
            sum(rate(ki_ana_learning_consent_total{kind="prompt"}[10m]))
            /
            clamp_min(sum(rate(ki_ana_chat_answer_duration_seconds_count[10m])), 1)
          ) > 0.30
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Consent prompt rate fast burn (>30%)"
          description: "Consent prompts elevated over last 10m."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityConsentPromptRateHighSlow
        expr: |
          (
            sum(rate(ki_ana_learning_consent_total{kind="prompt"}[2h]))
            /
            clamp_min(sum(rate(ki_ana_chat_answer_duration_seconds_count[2h])), 1)
          ) > 0.20
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Consent prompt rate slow burn (>20%)"
          description: "Consent prompts elevated over last 2h."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      # ---- SLO-5: Negative feedback rate ---------------------------------
      - alert: KiAnaQualityNegativeFeedbackRateHighFast
        expr: |
          (
            sum(rate(ki_ana_chat_feedback_total{status="negative"}[10m]))
            /
            clamp_min(sum(rate(ki_ana_chat_feedback_total[10m])), 1)
          ) > 0.08
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Negative feedback rate fast burn (>8%)"
          description: "Negative feedback elevated over last 10m."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

      - alert: KiAnaQualityNegativeFeedbackRateHighSlow
        expr: |
          (
            sum(rate(ki_ana_chat_feedback_total{status="negative"}[2h]))
            /
            clamp_min(sum(rate(ki_ana_chat_feedback_total[2h])), 1)
          ) > 0.05
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Negative feedback rate slow burn (>5%)"
          description: "Negative feedback elevated over last 2h."
          runbook: "ops/runbooks/quality_slos.md"
          dashboard: "monitoring/grafana/dashboards/kiana-quality.json"

  - name: ki-ana-probes
    rules:
      - alert: KiAnaPublicPingDown
        expr: probe_success{job="blackbox"} == 0
        for: 2m
        labels:
          severity: page
        annotations:
          summary: "KI_ana public endpoint probe failed"
          description: "Blackbox probe failing for {{ $labels.instance }}"
